# [End-to-End Memory Networks 2015](https://arxiv.org/pdf/1503.08895.pdf)
#datascience #machinelearning

Recent trend in deep learning, using explicit storage and the notion of attention
- attention mechanisms in Neural Networks is loosely based on human visual attention
  - focus on different regions of the image
- this paper focuses on architecture for RNNs, where the recurrence depends on reads from large external memory
